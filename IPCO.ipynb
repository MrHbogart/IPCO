{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IPCO.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "in this project, the goal is to find a well trained deep learning model that outputs pollution factors of EF7 engine besed on load on engine and angel of CVVT camshaft and some other parameters.\n",
        "for this project i used keras over Tensorflow with dense neural network.\n",
        "to tune hyper parameters of network, i used kers-tuner."
      ],
      "metadata": {
        "id": "CWQavsQOA_Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94tqSIDujYO",
        "outputId": "25ccc035-5d98-4bb9-a7fd-dc96b1c57835"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 135 kB 26.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 64.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"GPUs Available: \", len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "162bQAR_uiSr",
        "outputId": "1a34ffb8-9e44-4858-90fb-d3d0463a8ecf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "raw data is excel sheets provided by IPCO Test center.\n",
        "we read those sheets with pandas dataframe"
      ],
      "metadata": {
        "id": "Irrgs8zVB8CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "for i in range(0, 13, 2):\n",
        "    dfs.append(pd.read_excel(\"/content/drive/MyDrive/IPCO/small.xlsx\", sheet_name=i).iloc[3:, :])"
      ],
      "metadata": {
        "id": "WIJEJ_6nnSL_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filtering needed columns and concat all sheets to one dataframe"
      ],
      "metadata": {
        "id": "16p1Ff08CNVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat(dfs)\n",
        "df = df.iloc[:, [1, 2, 3, 5, 6, 7, 8, 9, 10, 18, 20, 24, 27]]\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms6UF2dLsI4q",
        "outputId": "c9210755-e284-40a0-efee-98200635ad7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1640, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "these data contains a lot of nan, so we have to clean data and try to prepare\n",
        "as much data as we can."
      ],
      "metadata": {
        "id": "1A6KqQ6xCVcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace = True)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCbwMTIzwNry",
        "outputId": "d5028477-c9b5-4430-bd3f-c6be3576f538"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(684, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "need all features to be numeric"
      ],
      "metadata": {
        "id": "79D-tEIRCmPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.apply(pd.to_numeric)"
      ],
      "metadata": {
        "id": "Yuj71SgDyKJb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "spliting input and output data"
      ],
      "metadata": {
        "id": "P4GsD3RyCp1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,[0, 1, 3, 4, 5]].copy()\n",
        "Y = df.iloc[:,[2, 6, 7, 8, 9, 10, 11, 12]].copy()"
      ],
      "metadata": {
        "id": "8Wb8PWCxnaiD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjM_i6Q_rl5K",
        "outputId": "4a6ab02a-2704-477d-c29d-0898eb6efc96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(684, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizing input features with sklearn"
      ],
      "metadata": {
        "id": "ZsGz-9SDCvnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "X = X.values #returns a numpy array\n",
        "X_min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = X_min_max_scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "ezFI0gJst3Ga"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizing output data with sklearn"
      ],
      "metadata": {
        "id": "pb-msSvgC4Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Y.values #returns a numpy array\n",
        "Y_min_max_scaler = preprocessing.MinMaxScaler()\n",
        "y_scaled = Y_min_max_scaler.fit_transform(Y)"
      ],
      "metadata": {
        "id": "KuOtQYY0cGjC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ovnE6OzuVQl",
        "outputId": "16c5f3ef-7d21-4a0e-a96b-3fd8e6b0c8ed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(684, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for evaluation of how well the model predicts, we need some data to be test data, so we split data to train and test data with test size of 0.2\n",
        "for this perpose i used train_test_split function from sklearn model selection utils."
      ],
      "metadata": {
        "id": "2QQR0a76C781"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QfSAztIuu_Hs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3zN8OP4bsu9",
        "outputId": "04511ff8-935d-48c4-d878-4498b80f7ada"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49975012, 0.82241598, 0.99878917, 0.50165274, 0.33272149],\n",
              "       [0.24987506, 0.65228375, 0.251034  , 0.99837744, 0.26135501],\n",
              "       [0.99950025, 0.31201929, 0.49945145, 0.99467097, 0.42683193],\n",
              "       ...,\n",
              "       [0.24987506, 0.82241598, 0.24855404, 0.50221649, 0.18021673],\n",
              "       [0.49975012, 0.65228375, 0.74879676, 0.0060429 , 0.33793827],\n",
              "       [0.        , 0.82241598, 0.24987017, 0.25199648, 0.11196355]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this section of code i used kers_tuner to find the best hyper parameters"
      ],
      "metadata": {
        "id": "kLahOEzfDlr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def model_builder(hp):\n",
        "#     input = Input(shape=(X_train.shape[1]), name=\"Input\")\n",
        "\n",
        "#     x = Dense(256, activation=\"ReLU\")(input)\n",
        "#     x = Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "#     x = Dense(256, activation=\"ReLU\")(x)\n",
        "#     x = Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "#     x = Dense(256, activation=\"ReLU\")(x)\n",
        "#     x = Dropout(0.2)(x)\n",
        "\n",
        "#     x = Dense(256, activation=\"ReLU\")(x)\n",
        "#     x = Dropout(0.2)(x)\n",
        "\n",
        "#     x = Dense(256, activation=\"ReLU\")(x)\n",
        "\n",
        "#     # x = Dense(256, activation=\"ReLU\")(x)\n",
        "\n",
        "\n",
        "#     output = Dense(y_train.shape[1])(x)\n",
        "\n",
        "#     model = Model(inputs=input, outputs=output)\n",
        "    \n",
        "\n",
        "\n",
        "#     # Tune the learning rate for the optimizer\n",
        "#     # hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
        "\n",
        "#     # hp_decay = hp.Choice('decay', values=[0.99, 0.95, 0.9])\n",
        "\n",
        "#     # opt = tf.keras.optimizers.Adam(\n",
        "#     #     learning_rate=hp_learning_rate,\n",
        "#     #     decay=hp_decay\n",
        "#     # )\n",
        "\n",
        "#     model.compile(optimizer=\"adam\",\n",
        "#                 loss='mse',\n",
        "#                 metrics=['mse'])\n",
        "\n",
        "\n",
        "\n",
        "#     # print(model.summary())\n",
        "#     plot_model(model, to_file='model.png', show_shapes=True)\n",
        "#     return model"
      ],
      "metadata": {
        "id": "uw5WjcbTua5y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "removing the directory of previous attempts to find the best model hyperparameters"
      ],
      "metadata": {
        "id": "56pzyYupDsfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -r /content/drive/MyDrive/IPCO/kat/IPCO"
      ],
      "metadata": {
        "id": "2mb0WzW6upud"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_mse',\n",
        "                     max_epochs=100,\n",
        "                     factor=16,\n",
        "                     directory='/content/drive/MyDrive/IPCO/kat',\n",
        "                     project_name='IPCO')"
      ],
      "metadata": {
        "id": "7BZojNV1utBp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_mse', patience=4)"
      ],
      "metadata": {
        "id": "COkQhUdIuvQW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, validation_data=(X_test, y_test), callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "RkBX7yCiuxG1",
        "outputId": "f60a9c65-b113-4013-ece5-4760116d63e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 04s]\n",
            "val_mse: 0.0263019111007452\n",
            "\n",
            "Best val_mse So Far: 0.02407967858016491\n",
            "Total elapsed time: 00h 00m 36s\n",
            "\n",
            "Search: Running Trial #11\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "1e-05             |0.01              |learning_rate\n",
            "0.9               |0.99              |decay\n",
            "7                 |7                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "1                 |1                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'gradient_tape/mean_squared_error/Shape' has no attr named '_class'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-91994cbaa245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    785\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 786\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2983\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2984\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \"\"\"\n\u001b[1;32m    530\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 531\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     self._assert_valid_dtypes([\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;31m# more sense.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       output_shape_kept_dims = math_ops.reduced_shape(input_shape,\n\u001b[0;32m--> 212\u001b[0;31m                                                       op.inputs[1])\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape_kept_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduced_shape\u001b[0;34m(input_shape, axes)\u001b[0m\n\u001b[1;32m   4507\u001b[0m   \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [1, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m   \u001b[0minput_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m   \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_rank\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minput_rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m   \u001b[0maxes_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msize\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    774\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \"\"\"\n\u001b[0;32m--> 776\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msize_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msize_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 268\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m--> 290\u001b[0;31m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3785\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3872\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3874\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2690\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2691\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best_hps.values"
      ],
      "metadata": {
        "id": "o5JPUZTHuzTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best_model = tuner.get_best_models()[0]"
      ],
      "metadata": {
        "id": "L-2n2-vzu1V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's build the best model with adam optimizer and mean square error as loss function"
      ],
      "metadata": {
        "id": "d0brGzKTD5I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model():\n",
        "    input = Input(shape=(X_train.shape[1]), name=\"Input\")\n",
        "\n",
        "    x = Dense(256, activation=\"ReLU\")(input)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "    x = Dense(256, activation=\"ReLU\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "\n",
        "    x = Dense(256, activation=\"ReLU\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(256, activation=\"ReLU\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(256, activation=\"ReLU\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(256, activation=\"ReLU\")(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Dense(256, activation=\"ReLU\")(x)\n",
        "\n",
        "    # x = Dense(256, activation=\"ReLU\")(x)\n",
        "\n",
        "\n",
        "    output = Dense(y_train.shape[1])(x)\n",
        "\n",
        "    model = Model(inputs=input, outputs=output)\n",
        "    \n",
        "\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "\n",
        "\n",
        "    # opt = tf.keras.optimizers.Adam(\n",
        "    #     learning_rate=1e-1,\n",
        "    #     decay=0.99\n",
        "    # )\n",
        "\n",
        "    model.compile(optimizer=\"adam\",\n",
        "                loss='mse',\n",
        "                metrics=['mse'])\n",
        "\n",
        "\n",
        "\n",
        "    # print(model.summary())\n",
        "    plot_model(model, to_file='model.png', show_shapes=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "TWQuLBYe3pVm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's train the model for 1024 epochs"
      ],
      "metadata": {
        "id": "ownUTwoaEC5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model()\n",
        "history = model.fit(x=X_train, y=y_train, batch_size=128, epochs=1024,\n",
        "                    verbose=1, validation_data=[X_test, y_test])"
      ],
      "metadata": {
        "id": "z1VBKd9Gu28A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f91c7d-b35b-4f17-c467-f3120d89616c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1024\n",
            "5/5 [==============================] - 1s 44ms/step - loss: 0.1317 - mse: 0.1317 - val_loss: 0.0481 - val_mse: 0.0481\n",
            "Epoch 2/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.0573 - val_mse: 0.0573\n",
            "Epoch 3/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0257 - val_mse: 0.0257\n",
            "Epoch 4/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0331 - val_mse: 0.0331\n",
            "Epoch 5/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0245 - val_mse: 0.0245\n",
            "Epoch 6/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 7/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0214 - val_mse: 0.0214\n",
            "Epoch 8/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0222 - val_mse: 0.0222\n",
            "Epoch 9/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0199 - val_mse: 0.0199\n",
            "Epoch 10/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0168 - val_mse: 0.0168\n",
            "Epoch 11/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0186 - val_mse: 0.0186\n",
            "Epoch 12/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 13/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 14/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 15/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 16/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 17/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 18/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 19/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 20/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 21/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 22/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0064 - val_mse: 0.0064\n",
            "Epoch 23/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 24/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 25/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0074 - val_mse: 0.0074\n",
            "Epoch 26/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 27/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 28/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0068 - val_mse: 0.0068\n",
            "Epoch 29/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0071 - val_mse: 0.0071\n",
            "Epoch 30/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 31/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0059 - val_mse: 0.0059\n",
            "Epoch 32/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0064 - val_mse: 0.0064\n",
            "Epoch 33/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0074 - val_mse: 0.0074\n",
            "Epoch 34/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0054 - val_mse: 0.0054\n",
            "Epoch 35/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 36/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0068 - val_mse: 0.0068\n",
            "Epoch 37/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0064 - val_mse: 0.0064\n",
            "Epoch 38/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0065 - val_mse: 0.0065\n",
            "Epoch 39/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 40/1024\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 41/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 42/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0066 - val_mse: 0.0066\n",
            "Epoch 43/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 44/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0061 - val_mse: 0.0061\n",
            "Epoch 45/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 46/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 47/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 48/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 49/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 50/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0051 - val_mse: 0.0051\n",
            "Epoch 51/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0055 - val_mse: 0.0055\n",
            "Epoch 52/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0048 - val_mse: 0.0048\n",
            "Epoch 53/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 54/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0049 - val_mse: 0.0049\n",
            "Epoch 55/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 56/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 57/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 58/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 59/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 60/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0056 - val_mse: 0.0056\n",
            "Epoch 61/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0052 - val_mse: 0.0052\n",
            "Epoch 62/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 63/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0059 - val_mse: 0.0059\n",
            "Epoch 64/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 65/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0044 - val_mse: 0.0044\n",
            "Epoch 66/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0050 - val_mse: 0.0050\n",
            "Epoch 67/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 68/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 69/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0045 - val_mse: 0.0045\n",
            "Epoch 70/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 71/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 72/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 73/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 74/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0043 - val_mse: 0.0043\n",
            "Epoch 75/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 76/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0047 - val_mse: 0.0047\n",
            "Epoch 77/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 78/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 79/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 80/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0046 - val_mse: 0.0046\n",
            "Epoch 81/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 82/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0042 - val_mse: 0.0042\n",
            "Epoch 83/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 84/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 85/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 86/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 87/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 88/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 89/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 90/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 91/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 92/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0036 - val_mse: 0.0036\n",
            "Epoch 93/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 94/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 95/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 96/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 97/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 98/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 99/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0038 - val_mse: 0.0038\n",
            "Epoch 100/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 101/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0040 - val_mse: 0.0040\n",
            "Epoch 102/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 103/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0037 - val_mse: 0.0037\n",
            "Epoch 104/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 105/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 106/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 107/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 108/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 109/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 110/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0039 - val_mse: 0.0039\n",
            "Epoch 111/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0030 - val_mse: 0.0030\n",
            "Epoch 112/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 113/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 114/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 115/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 116/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0030 - val_mse: 0.0030\n",
            "Epoch 117/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 118/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 119/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 120/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 121/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 122/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 123/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 124/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 125/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0029 - val_mse: 0.0029\n",
            "Epoch 126/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0035 - val_mse: 0.0035\n",
            "Epoch 127/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0030 - val_mse: 0.0030\n",
            "Epoch 128/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 129/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0034 - val_mse: 0.0034\n",
            "Epoch 130/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 131/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 132/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 133/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 134/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 135/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 136/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0029 - val_mse: 0.0029\n",
            "Epoch 137/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 138/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 139/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 140/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 141/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 142/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 143/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0029 - val_mse: 0.0029\n",
            "Epoch 144/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 145/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 146/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 147/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 148/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0029 - val_mse: 0.0029\n",
            "Epoch 149/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 150/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 151/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0030 - val_mse: 0.0030\n",
            "Epoch 152/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 153/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 154/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 155/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 156/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 157/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 158/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 159/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 160/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 161/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 162/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 163/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 164/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 165/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 166/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 167/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 168/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 169/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 170/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 171/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 172/1024\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 173/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 174/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 175/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 176/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 177/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 178/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 179/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 180/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 181/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 182/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 183/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 184/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 185/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 186/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 187/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 188/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 189/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 190/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 191/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 192/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 193/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 194/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 195/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 196/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 197/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 198/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 199/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 200/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 201/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 202/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 203/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 204/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 205/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 206/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 207/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 208/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 209/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 210/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 211/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 212/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 213/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 214/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 215/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 216/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 217/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 218/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 219/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 220/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 221/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 222/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 223/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 224/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 225/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 226/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 227/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 228/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 229/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 230/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 231/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 232/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 233/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 234/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 235/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 236/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 237/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 238/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 239/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 240/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 241/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 242/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 243/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 244/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 245/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 246/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 247/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 248/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 249/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 250/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 251/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 252/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 253/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 254/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 255/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 256/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 257/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 258/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 259/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 260/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 261/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 262/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 263/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 264/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 265/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 266/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 267/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 268/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 269/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 270/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 271/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 272/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 273/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 274/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 275/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 276/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 277/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 278/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 279/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 280/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 281/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 282/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 283/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 284/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 285/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 286/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 287/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 288/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 289/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 290/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 291/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 292/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 293/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 294/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 295/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 296/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 297/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 298/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 299/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 300/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 301/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 302/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 303/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 304/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 305/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 306/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 307/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 308/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 309/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 310/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 311/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 312/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 313/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 314/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 315/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 316/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 317/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 318/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 319/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 320/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 321/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 322/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 323/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 324/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 325/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 326/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 327/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 328/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 329/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 330/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 331/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 332/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 333/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 334/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 335/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 336/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 337/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 338/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 339/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 340/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 341/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 342/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 343/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 344/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 345/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 346/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 347/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 348/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 349/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 350/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 351/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 352/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 353/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 354/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 355/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 356/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 357/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 358/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 359/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 360/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 361/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 362/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 363/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 364/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 365/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 366/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 367/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 368/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 369/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 370/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 371/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 372/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 373/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 374/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 375/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 376/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 377/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 378/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 379/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 380/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 381/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 382/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 383/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 384/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 385/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 386/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 387/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 388/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 389/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 390/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 391/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 392/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 393/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 394/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 395/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 396/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 397/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 398/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 399/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 400/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 401/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 402/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 403/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 404/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 405/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 406/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 407/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 408/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 409/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 410/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 411/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 412/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 413/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 414/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 415/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 416/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 417/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 418/1024\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 419/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 420/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 421/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 422/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 423/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 424/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 425/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 426/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 427/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 428/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 429/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 430/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 431/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 432/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 433/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 434/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 435/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 436/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 437/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 438/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 439/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 440/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 441/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 442/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 443/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 444/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 445/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 446/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 447/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 448/1024\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 449/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 450/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 451/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 452/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 453/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 454/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 455/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 456/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 457/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 458/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 459/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 460/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 461/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 462/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 463/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 464/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 465/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 466/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 467/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 468/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 469/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 470/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 471/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 472/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 473/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 474/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 475/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 476/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 477/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 478/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 479/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 480/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 481/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 482/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 483/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 484/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 485/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 486/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 487/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 488/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 489/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 490/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 491/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 492/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 493/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 494/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 495/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 496/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 497/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 498/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 499/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 500/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 501/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 502/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 503/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 504/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 505/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 506/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 507/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 508/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 509/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 510/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 511/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 512/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 513/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 514/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 515/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 516/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 517/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 518/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 519/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 520/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 521/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 522/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 523/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 524/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 525/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 526/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 527/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 528/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 529/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 530/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 531/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 532/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 533/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 534/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 535/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 536/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 537/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 538/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 539/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 540/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 541/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 542/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 543/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 544/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 545/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 546/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 547/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 548/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 549/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 550/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9720e-04 - mse: 8.9720e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 551/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 552/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 553/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 554/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 555/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 556/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 557/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 558/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 559/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 560/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 561/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 562/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 563/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 564/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.9322e-04 - mse: 9.9322e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 565/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 566/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 567/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 568/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.0848e-04 - mse: 9.0848e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 569/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 570/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 571/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 572/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 573/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 574/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 575/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 576/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 577/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 578/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 579/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 580/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 581/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.3654e-04 - mse: 9.3654e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 582/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 583/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 584/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.9786e-04 - mse: 9.9786e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 585/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 586/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6488e-04 - mse: 8.6488e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 587/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 588/1024\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 8.6042e-04 - mse: 8.6042e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 589/1024\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 590/1024\n",
            "5/5 [==============================] - 0s 30ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 591/1024\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 9.9967e-04 - mse: 9.9967e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 592/1024\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 593/1024\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 594/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 595/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 596/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 597/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 598/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 599/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 600/1024\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 9.3013e-04 - mse: 9.3013e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 601/1024\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 602/1024\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 9.6277e-04 - mse: 9.6277e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 603/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8.7696e-04 - mse: 8.7696e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 604/1024\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 9.2741e-04 - mse: 9.2741e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 605/1024\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 606/1024\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 9.2880e-04 - mse: 9.2880e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 607/1024\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 608/1024\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 8.8877e-04 - mse: 8.8877e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 609/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.9118e-04 - mse: 9.9118e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 610/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.3764e-04 - mse: 8.3764e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 611/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.4046e-04 - mse: 9.4046e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 612/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.8399e-04 - mse: 8.8399e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 613/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.2959e-04 - mse: 9.2959e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 614/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9500e-04 - mse: 8.9500e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 615/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.0323e-04 - mse: 8.0323e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 616/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.5243e-04 - mse: 9.5243e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 617/1024\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 8.2834e-04 - mse: 8.2834e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 618/1024\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 619/1024\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 8.7094e-04 - mse: 8.7094e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 620/1024\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 8.7252e-04 - mse: 8.7252e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 621/1024\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 7.6796e-04 - mse: 7.6796e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 622/1024\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 8.1329e-04 - mse: 8.1329e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 623/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.7865e-04 - mse: 8.7865e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 624/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.2536e-04 - mse: 8.2536e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 625/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.9301e-04 - mse: 7.9301e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 626/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 627/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.4976e-04 - mse: 8.4976e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 628/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 8.5638e-04 - mse: 8.5638e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 629/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.3330e-04 - mse: 8.3330e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 630/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.0629e-04 - mse: 9.0629e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 631/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.3438e-04 - mse: 8.3438e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 632/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 633/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.7972e-04 - mse: 9.7972e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 634/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.0655e-04 - mse: 9.0655e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 635/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.5406e-04 - mse: 8.5406e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 636/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.5146e-04 - mse: 8.5146e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 637/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.2746e-04 - mse: 9.2746e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 638/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.8442e-04 - mse: 9.8442e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 639/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.8236e-04 - mse: 7.8236e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 640/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.2463e-04 - mse: 8.2463e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 641/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.9653e-04 - mse: 7.9653e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 642/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.8208e-04 - mse: 9.8208e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 643/1024\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 9.7721e-04 - mse: 9.7721e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 644/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 645/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.4090e-04 - mse: 8.4090e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 646/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.7463e-04 - mse: 8.7463e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 647/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.6825e-04 - mse: 8.6825e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 648/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9226e-04 - mse: 8.9226e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 649/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.4964e-04 - mse: 7.4964e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 650/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 651/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.8377e-04 - mse: 9.8377e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 652/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.9253e-04 - mse: 9.9253e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 653/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 654/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 655/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 656/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.4879e-04 - mse: 9.4879e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 657/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.5045e-04 - mse: 9.5045e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 658/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.2285e-04 - mse: 9.2285e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 659/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1897e-04 - mse: 8.1897e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 660/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.3345e-04 - mse: 8.3345e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 661/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.4902e-04 - mse: 7.4902e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 662/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.2761e-04 - mse: 8.2761e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 663/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.3528e-04 - mse: 8.3528e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 664/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 8.3414e-04 - mse: 8.3414e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 665/1024\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 9.8723e-04 - mse: 9.8723e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 666/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.5745e-04 - mse: 8.5745e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 667/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.6768e-04 - mse: 9.6768e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 668/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9394e-04 - mse: 8.9394e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 669/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 670/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.8762e-04 - mse: 9.8762e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 671/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 8.5910e-04 - mse: 8.5910e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 672/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 673/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 674/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 675/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 676/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 677/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.8053e-04 - mse: 9.8053e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 678/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.0310e-04 - mse: 9.0310e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 679/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.8185e-04 - mse: 9.8185e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 680/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.9883e-04 - mse: 7.9883e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 681/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 682/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6353e-04 - mse: 8.6353e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 683/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.7820e-04 - mse: 8.7820e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 684/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 685/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.2258e-04 - mse: 8.2258e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 686/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.2621e-04 - mse: 8.2621e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 687/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.2843e-04 - mse: 9.2843e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 688/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.0679e-04 - mse: 7.0679e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 689/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.3149e-04 - mse: 8.3149e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 690/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9775e-04 - mse: 8.9775e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 691/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 692/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 693/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.0231e-04 - mse: 9.0231e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 694/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 695/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.5833e-04 - mse: 8.5833e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 696/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.0213e-04 - mse: 8.0213e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 697/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 698/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.6523e-04 - mse: 9.6523e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 699/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.8360e-04 - mse: 8.8360e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 700/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.6873e-04 - mse: 8.6873e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 701/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.1311e-04 - mse: 8.1311e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 702/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.2362e-04 - mse: 8.2362e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 703/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.8645e-04 - mse: 8.8645e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 704/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.3529e-04 - mse: 7.3529e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 705/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.3361e-04 - mse: 7.3361e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 706/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.1429e-04 - mse: 9.1429e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 707/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.7455e-04 - mse: 8.7455e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 708/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.9024e-04 - mse: 8.9024e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 709/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.1120e-04 - mse: 8.1120e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 710/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.5054e-04 - mse: 9.5054e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 711/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.6276e-04 - mse: 8.6276e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 712/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.3539e-04 - mse: 9.3539e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 713/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1910e-04 - mse: 7.1910e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 714/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.4204e-04 - mse: 9.4204e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 715/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.6098e-04 - mse: 6.6098e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 716/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7543e-04 - mse: 6.7543e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 717/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7860e-04 - mse: 7.7860e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 718/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.5577e-04 - mse: 7.5577e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 719/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.0252e-04 - mse: 7.0252e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 720/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.3067e-04 - mse: 8.3067e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 721/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.9038e-04 - mse: 7.9038e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 722/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.2574e-04 - mse: 6.2574e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 723/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 724/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.5183e-04 - mse: 7.5183e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 725/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.1580e-04 - mse: 9.1580e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 726/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7556e-04 - mse: 7.7556e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 727/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.3438e-04 - mse: 6.3438e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 728/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.3448e-04 - mse: 7.3448e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 729/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.5132e-04 - mse: 7.5132e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 730/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1074e-04 - mse: 7.1074e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 731/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.0831e-04 - mse: 8.0831e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 732/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.5988e-04 - mse: 7.5988e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 733/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.9660e-04 - mse: 7.9660e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 734/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.6593e-04 - mse: 6.6593e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 735/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.2972e-04 - mse: 7.2972e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 736/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.6056e-04 - mse: 7.6056e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 737/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8694e-04 - mse: 6.8694e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 738/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.5271e-04 - mse: 6.5271e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 739/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.2465e-04 - mse: 7.2465e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 740/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.2112e-04 - mse: 7.2112e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 741/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8959e-04 - mse: 6.8959e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 742/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7169e-04 - mse: 7.7169e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 743/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.6055e-04 - mse: 8.6055e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 744/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.8140e-04 - mse: 8.8140e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 745/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.5535e-04 - mse: 6.5535e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 746/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.5223e-04 - mse: 8.5223e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 747/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.8621e-04 - mse: 6.8621e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 748/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.4199e-04 - mse: 9.4199e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 749/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1899e-04 - mse: 7.1899e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 750/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.5413e-04 - mse: 7.5413e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 751/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8130e-04 - mse: 6.8130e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 752/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 753/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.1174e-04 - mse: 9.1174e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 754/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 755/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.1908e-04 - mse: 9.1908e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 756/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.5364e-04 - mse: 9.5364e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 757/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.7519e-04 - mse: 8.7519e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 758/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 759/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.9622e-04 - mse: 8.9622e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 760/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.8335e-04 - mse: 8.8335e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 761/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.5291e-04 - mse: 7.5291e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 762/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7331e-04 - mse: 7.7331e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 763/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.0824e-04 - mse: 8.0824e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 764/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.6793e-04 - mse: 9.6793e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 765/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 766/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.6816e-04 - mse: 7.6816e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 767/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.1198e-04 - mse: 9.1198e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 768/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 769/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.2633e-04 - mse: 9.2633e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 770/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 771/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 772/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 773/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.7111e-04 - mse: 7.7111e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 774/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.8332e-04 - mse: 8.8332e-04 - val_loss: 0.0027 - val_mse: 0.0027\n",
            "Epoch 775/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.3392e-04 - mse: 9.3392e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 776/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 777/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 778/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 779/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.0467e-04 - mse: 9.0467e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 780/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.0813e-04 - mse: 9.0813e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 781/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6057e-04 - mse: 8.6057e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 782/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.4628e-04 - mse: 8.4628e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 783/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.3457e-04 - mse: 8.3457e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 784/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.5799e-04 - mse: 9.5799e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 785/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6573e-04 - mse: 8.6573e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 786/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.9952e-04 - mse: 8.9952e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 787/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.4400e-04 - mse: 7.4400e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 788/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.4853e-04 - mse: 8.4853e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 789/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.7526e-04 - mse: 8.7526e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 790/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1710e-04 - mse: 8.1710e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 791/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 792/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.4261e-04 - mse: 9.4261e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 793/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 794/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 795/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 796/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.7028e-04 - mse: 9.7028e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 797/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 798/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9818e-04 - mse: 8.9818e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 799/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.4246e-04 - mse: 8.4246e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 800/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 801/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.8537e-04 - mse: 7.8537e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 802/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7306e-04 - mse: 7.7306e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 803/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.1536e-04 - mse: 7.1536e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 804/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.4841e-04 - mse: 7.4841e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 805/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.2271e-04 - mse: 7.2271e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 806/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.2911e-04 - mse: 6.2911e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 807/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9378e-04 - mse: 6.9378e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 808/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.0412e-04 - mse: 7.0412e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 809/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.1430e-04 - mse: 7.1430e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 810/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.2230e-04 - mse: 7.2230e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 811/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.8121e-04 - mse: 8.8121e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 812/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.8774e-04 - mse: 7.8774e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 813/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6543e-04 - mse: 8.6543e-04 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 814/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.7581e-04 - mse: 7.7581e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 815/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.8652e-04 - mse: 8.8652e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 816/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.4179e-04 - mse: 8.4179e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 817/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.4032e-04 - mse: 9.4032e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 818/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.0630e-04 - mse: 7.0630e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 819/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1059e-04 - mse: 7.1059e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 820/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.3480e-04 - mse: 7.3480e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 821/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8425e-04 - mse: 6.8425e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 822/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6039e-04 - mse: 8.6039e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 823/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 824/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.1237e-04 - mse: 9.1237e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 825/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.5736e-04 - mse: 9.5736e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 826/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6853e-04 - mse: 8.6853e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 827/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.9935e-04 - mse: 7.9935e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 828/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.4192e-04 - mse: 8.4192e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 829/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.5403e-04 - mse: 7.5403e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 830/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.4284e-04 - mse: 7.4284e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 831/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.8122e-04 - mse: 7.8122e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 832/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 833/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.2513e-04 - mse: 8.2513e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 834/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 835/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.0497e-04 - mse: 9.0497e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 836/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.1328e-04 - mse: 9.1328e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 837/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.2598e-04 - mse: 9.2598e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 838/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 9.1792e-04 - mse: 9.1792e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 839/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.0927e-04 - mse: 7.0927e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 840/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.5850e-04 - mse: 7.5850e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 841/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.0274e-04 - mse: 9.0274e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 842/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.6275e-04 - mse: 6.6275e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 843/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.5939e-04 - mse: 8.5939e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 844/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6514e-04 - mse: 8.6514e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 845/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.1536e-04 - mse: 8.1536e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 846/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.0554e-04 - mse: 8.0554e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 847/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1198e-04 - mse: 7.1198e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 848/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9757e-04 - mse: 6.9757e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 849/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.1160e-04 - mse: 6.1160e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 850/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.3794e-04 - mse: 7.3794e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 851/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.6729e-04 - mse: 6.6729e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 852/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.9998e-04 - mse: 6.9998e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 853/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8871e-04 - mse: 6.8871e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 854/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1272e-04 - mse: 7.1272e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 855/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.9583e-04 - mse: 5.9583e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 856/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.3417e-04 - mse: 6.3417e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 857/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.4587e-04 - mse: 6.4587e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 858/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.9528e-04 - mse: 5.9528e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 859/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1849e-04 - mse: 7.1849e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 860/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7573e-04 - mse: 6.7573e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 861/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.0078e-04 - mse: 8.0078e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 862/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.4362e-04 - mse: 6.4362e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 863/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 7.0332e-04 - mse: 7.0332e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 864/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.8316e-04 - mse: 6.8316e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 865/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7181e-04 - mse: 7.7181e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 866/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.5106e-04 - mse: 6.5106e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 867/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1021e-04 - mse: 7.1021e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 868/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8939e-04 - mse: 6.8939e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 869/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7857e-04 - mse: 7.7857e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 870/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.5575e-04 - mse: 8.5575e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 871/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.0546e-04 - mse: 7.0546e-04 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 872/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 873/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.1233e-04 - mse: 8.1233e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 874/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 875/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.6900e-04 - mse: 6.6900e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 876/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.0773e-04 - mse: 7.0773e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 877/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8928e-04 - mse: 6.8928e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 878/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.8660e-04 - mse: 7.8660e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 879/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8773e-04 - mse: 6.8773e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 880/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1187e-04 - mse: 8.1187e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 881/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 882/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 883/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 884/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 885/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.7846e-04 - mse: 9.7846e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 886/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.2624e-04 - mse: 8.2624e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 887/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.3409e-04 - mse: 8.3409e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 888/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.8535e-04 - mse: 7.8535e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 889/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.8669e-04 - mse: 7.8669e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 890/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 891/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 892/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.4986e-04 - mse: 9.4986e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 893/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 894/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 895/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.4795e-04 - mse: 9.4795e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 896/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.1517e-04 - mse: 8.1517e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 897/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 898/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.6112e-04 - mse: 7.6112e-04 - val_loss: 0.0022 - val_mse: 0.0022\n",
            "Epoch 899/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9043e-04 - mse: 8.9043e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 900/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.2502e-04 - mse: 8.2502e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 901/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.1860e-04 - mse: 7.1860e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 902/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.0755e-04 - mse: 7.0755e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 903/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.9112e-04 - mse: 7.9112e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 904/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0028 - val_mse: 0.0028\n",
            "Epoch 905/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.7467e-04 - mse: 9.7467e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 906/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.4520e-04 - mse: 8.4520e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 907/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 908/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.5577e-04 - mse: 9.5577e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 909/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.8757e-04 - mse: 7.8757e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 910/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.4240e-04 - mse: 7.4240e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 911/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.6089e-04 - mse: 9.6089e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 912/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9246e-04 - mse: 6.9246e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 913/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.6171e-04 - mse: 7.6171e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 914/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.9551e-04 - mse: 8.9551e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 915/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.0468e-04 - mse: 8.0468e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 916/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 917/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 918/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0041 - val_mse: 0.0041\n",
            "Epoch 919/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 920/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0021 - val_mse: 0.0021\n",
            "Epoch 921/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0024 - val_mse: 0.0024\n",
            "Epoch 922/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 923/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0031 - val_mse: 0.0031\n",
            "Epoch 924/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 925/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 926/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.9369e-04 - mse: 9.9369e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 927/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.0423e-04 - mse: 9.0423e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 928/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.4912e-04 - mse: 9.4912e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 929/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 9.7275e-04 - mse: 9.7275e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 930/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.8690e-04 - mse: 8.8690e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 931/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7256e-04 - mse: 7.7256e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 932/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9622e-04 - mse: 6.9622e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 933/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.3369e-04 - mse: 6.3369e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 934/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.5205e-04 - mse: 6.5205e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 935/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.8058e-04 - mse: 6.8058e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 936/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.1979e-04 - mse: 6.1979e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 937/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7703e-04 - mse: 6.7703e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 938/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.0647e-04 - mse: 6.0647e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 939/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.2261e-04 - mse: 6.2261e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 940/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.6652e-04 - mse: 6.6652e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 941/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9920e-04 - mse: 6.9920e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 942/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.7052e-04 - mse: 5.7052e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 943/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.6800e-04 - mse: 6.6800e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 944/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.3979e-04 - mse: 6.3979e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 945/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.2488e-04 - mse: 6.2488e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 946/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.9004e-04 - mse: 5.9004e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 947/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9990e-04 - mse: 6.9990e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 948/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5791e-04 - mse: 6.5791e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 949/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.0984e-04 - mse: 7.0984e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 950/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1899e-04 - mse: 7.1899e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 951/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.1274e-04 - mse: 6.1274e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 952/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.5422e-04 - mse: 7.5422e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 953/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.6216e-04 - mse: 5.6216e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 954/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.0468e-04 - mse: 7.0468e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 955/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.1816e-04 - mse: 6.1816e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 956/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.8064e-04 - mse: 9.8064e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 957/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 958/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.5607e-04 - mse: 9.5607e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 959/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.7372e-04 - mse: 8.7372e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 960/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.1927e-04 - mse: 9.1927e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 961/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7494e-04 - mse: 7.7494e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 962/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.2917e-04 - mse: 9.2917e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 963/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 7.9264e-04 - mse: 7.9264e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 964/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 7.7555e-04 - mse: 7.7555e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 965/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.6896e-04 - mse: 8.6896e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 966/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 6.6731e-04 - mse: 6.6731e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 967/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 7.2308e-04 - mse: 7.2308e-04 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 968/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.6363e-04 - mse: 8.6363e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 969/1024\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.4494e-04 - mse: 8.4494e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 970/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.6445e-04 - mse: 7.6445e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 971/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1022e-04 - mse: 7.1022e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 972/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.8130e-04 - mse: 6.8130e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 973/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.5034e-04 - mse: 6.5034e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 974/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.5773e-04 - mse: 7.5773e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 975/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7806e-04 - mse: 6.7806e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 976/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.9036e-04 - mse: 6.9036e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 977/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7154e-04 - mse: 5.7154e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 978/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.5471e-04 - mse: 5.5471e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 979/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.0010e-04 - mse: 6.0010e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 980/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.7897e-04 - mse: 5.7897e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 981/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.4109e-04 - mse: 6.4109e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 982/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.7515e-04 - mse: 6.7515e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 983/1024\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 6.8701e-04 - mse: 6.8701e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 984/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7461e-04 - mse: 5.7461e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 985/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.4523e-04 - mse: 5.4523e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 986/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.8958e-04 - mse: 5.8958e-04 - val_loss: 0.0020 - val_mse: 0.0020\n",
            "Epoch 987/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.1961e-04 - mse: 6.1961e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 988/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.5231e-04 - mse: 5.5231e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 989/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.1008e-04 - mse: 5.1008e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 990/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.1966e-04 - mse: 6.1966e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 991/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7985e-04 - mse: 5.7985e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 992/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.7885e-04 - mse: 5.7885e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 993/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.4532e-04 - mse: 5.4532e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 994/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.7408e-04 - mse: 5.7408e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 995/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.5505e-04 - mse: 5.5505e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 996/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.2383e-04 - mse: 7.2383e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 997/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.3287e-04 - mse: 6.3287e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 998/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.7220e-04 - mse: 5.7220e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 999/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.1182e-04 - mse: 7.1182e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1000/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.0695e-04 - mse: 6.0695e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1001/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.6153e-04 - mse: 5.6153e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1002/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.2657e-04 - mse: 6.2657e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1003/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.7142e-04 - mse: 5.7142e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1004/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 5.6895e-04 - mse: 5.6895e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 1005/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.7259e-04 - mse: 5.7259e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 1006/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 6.2633e-04 - mse: 6.2633e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1007/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.7350e-04 - mse: 5.7350e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1008/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.4951e-04 - mse: 5.4951e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 1009/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.9036e-04 - mse: 5.9036e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 1010/1024\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 6.7878e-04 - mse: 6.7878e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1011/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.0652e-04 - mse: 6.0652e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1012/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.7501e-04 - mse: 6.7501e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1013/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.9648e-04 - mse: 6.9648e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1014/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.5927e-04 - mse: 6.5927e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1015/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.8909e-04 - mse: 6.8909e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1016/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.9930e-04 - mse: 5.9930e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 1017/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.5745e-04 - mse: 6.5745e-04 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 1018/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.8628e-04 - mse: 5.8628e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1019/1024\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 6.7970e-04 - mse: 6.7970e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1020/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.3651e-04 - mse: 5.3651e-04 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 1021/1024\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 5.5341e-04 - mse: 5.5341e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1022/1024\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.4584e-04 - mse: 6.4584e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1023/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.8851e-04 - mse: 5.8851e-04 - val_loss: 0.0018 - val_mse: 0.0018\n",
            "Epoch 1024/1024\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.8099e-04 - mse: 5.8099e-04 - val_loss: 0.0019 - val_mse: 0.0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ploting the training history of the model is a good way to see how well it was gone"
      ],
      "metadata": {
        "id": "a9HZw0QKEHiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['mse'])\n",
        "plt.plot(history.history['val_mse'])\n",
        "plt.legend([\"train\", \"test\"])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('mean-square-error')\n",
        "plt.savefig(\"model_performance.jpg\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "pPWYUkauc1Au",
        "outputId": "a88b8411-27a9-4d95-a730-5024160d5668"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets predict with model and evaluate the performance"
      ],
      "metadata": {
        "id": "B8e-s2JcERl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test[50:51])\n",
        "# pred"
      ],
      "metadata": {
        "id": "nC1sRg0Ld5rR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test[50:51]"
      ],
      "metadata": {
        "id": "1Wmh8kbue0kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_min_max_scaler.inverse_transform(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEQdM4FoeXA3",
        "outputId": "a176eabe-6195-4ad2-ce2d-8ccaba77b030"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.3763181e+03,  8.8695981e-02,  1.7584779e+00,  9.4050491e-01,\n",
              "         8.3736896e+02,  8.8518652e+02, -4.0012320e+02,  7.5683929e+01]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_min_max_scaler.inverse_transform(y_test[50:51])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2suEfYgejSC",
        "outputId": "77bf79eb-8c78-43a7-deeb-969953684447"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.78700000e+02,  8.53514957e-02,  1.25648504e+00,\n",
              "         9.56643926e-01,  8.63559391e+02,  8.10408152e+02,\n",
              "        -4.76521394e+02,  7.59739744e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}